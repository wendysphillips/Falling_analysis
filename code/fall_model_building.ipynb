{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad18ae32",
   "metadata": {},
   "source": [
    "This notebook shows how to recode the encoded variables in the dataset to human-readable values. The files used in this notebook are available on the [data download page](https://www.drivendata.org/competitions/217/cdc-fall-narratives/data/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906a252-e621-4309-a03b-225c4c4a7805",
   "metadata": {},
   "source": [
    "Key findings\n",
    "\n",
    "### What are 2-3 takeaways from your exploration?\n",
    "\n",
    "### Summary of your approach\n",
    "\n",
    "- Describe the data source(s) you used (e.g., if supplementary or external data was used, how the data was subsetted, if at all).\n",
    "- What did you do and why (e.g., preprocessing, key features, algorithms you used, unique or novel aspects of your solution, etc.)?\n",
    "- What worked and what didn’t? How did you evaluate the performance of your approach?\n",
    "- What are some limitations of your analysis?\n",
    "\n",
    "### Visualizations\n",
    "\n",
    "Do you have any useful tables, charts, graphs, or visualizations from the process (e.g., exploring the data, testing different features, summarizing model performance, etc.)?\n",
    "\n",
    "\n",
    "Winners will be selected by a judging panel of domain experts and researchers. Submissions will be judged according to the following weighted criteria:\n",
    "\n",
    "- Novelty (35%)\n",
    "    - To what extent does this submission utilize creative, cutting-edge, or innovative techniques? This can be demonstrated in any or all parts of the submission (e.g., preprocessing, embeddings, models, visualizations).\n",
    "- Communication (25%)\n",
    "    - To what extent are findings clearly and effectively communicated? This includes both text and visuals.\n",
    "- Rigor (20%)\n",
    "    - To what extent is this submission based on appropriate and correctly implemented methods and approaches (e.g., preprocessing, embeddings, models) with adequate sample sizes?\n",
    "- Insight (20%)\n",
    "    - To what extent does this submission contain useful insights about the effectiveness of unsupervised machine learning methods at uncovering patterns in this data and/or informative findings that can advance the research on circumstances related to older adult falls?\n",
    "\n",
    "We know this is an open-ended challenge. To help, we are providing some guiding lines of inquiry to help you get started. Feel free to use these or try something completely different!\n",
    "\n",
    "- What information about falls is contained in the narrative but not captured by the other variables?  \n",
    "- What precipitating events — actions that happen right before the fall — can be identified?  \n",
    "- How do falls (e.g., severity, type of fall injury) and fall circumstances (e.g., precipitating event, activity involved) differ among various demographic groups (e.g., by race, sex, age)?  \n",
    "- Are there trends over time in the types of falls that occur?  \n",
    "- What kinds of people, places, or things are associated with more or more severe falls? Are there alternative explanations for these associations?\n",
    "- What risk factors are associated with falls?  \n",
    "- The goal of this challenge is to explore the application of unsupervised machine learning techniques to this dataset. Below are some examples of analysis that would be a good fit for this challenge, as well as examples of analysis that are not a good fit.\n",
    "\n",
    "Good fit\n",
    "\n",
    "- Remove words from the narratives that are found in other variables (e.g., male, female, body parts) and cluster the remaining text to identify what information is in the narratives that is not captured elsewhere. Then use word embeddings to remove similar words and repeat the analysis.\n",
    "- Design a way to identify the \"precipitating event\" before a fall (e.g., tripping on carpet) and compare differences in precipitating events among various demographic groups.\n",
    "- Explore various clustering algorithms using the provided embeddings. Use the ChatGPT API to produce summaries of the clusters. Compare the results of using the embeddings versus using more traditional bag-of-words preprocessing techniques (e.g., stop word and punctuation removal, stemming and lemmatization, and token weighting such as TF-IDF).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92c3d52-681a-4702-946a-58424d90ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b54147-4454-4311-bb57-1850a3f1871e",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a207f8a8-2cda-49f3-9dfa-a2c1ae9d62b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59c0b39-9bfb-4453-a9f7-6742d023f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.1\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6575f5-dd53-4c3c-8818-ee419cf62cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scispacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18501e0d-7920-492b-a259-fd0bc34bad42",
   "metadata": {},
   "source": [
    "# My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86b5ac4-823c-4b87-ab7d-34660b769528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file for reading\n",
    "with open('falling_tags_all.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571227da-2adb-4ed5-9fa8-4c24c873dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys_list = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba787529-a479-49cb-8454-071b180136c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe8a6d93-faac-4e7c-b94c-3f0b6afd4ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sc': [HITTING HIS HEAD ON THE SHARP EDGE OF A COFFEE TABLE]}\n",
      "{'sc': [HITTING REFRIGERATOR]}\n",
      "{'sc': [STRIKING HEAD ONTO THE KITCHEN SINK]}\n",
      "{'sc': [STRUCK HEAD ON A PIECE OF FURNITURE]}\n",
      "{'sc': [STRIKING FACE ON THE CORNER OF A PIECE OF FURNITURE]}\n",
      "{'sc': [STRUCK A CONCRETE PEDESTAL]}\n",
      "{'sc': [HITTING HEAD/FACE ON BATHROOM CABINET]}\n",
      "{'sc': [STRUCK HEAD ON THE TOILET]}\n",
      "{'sc': [HIT THE BACK OF HER HEAD ON THE CORNER OF HER DRESSER]}\n",
      "{'sc': [HITTING ARM ON THE BANISTER]}\n",
      "{'sc': [HIT HEAD ON A REFRIGERATOR DOOR]}\n",
      "{'sc': [INTO CABINET]}\n",
      "{'sc': [HIT HEAD ON THE WALL]}\n",
      "{'sc': [HITTING HEAD AGAINST THE STAIRS]}\n",
      "{'sc': [FELL BACK AGAINST BED FRAME]}\n",
      "{'sc': [FELL INTO A WALL]}\n",
      "{'sc': [HIT THE BACK OF HER HEAD ON THE CLOSET WALL]}\n",
      "{'sc': [INTO BUSHES,HIT HEAD]}\n",
      "{'sc': [STRIKING FACE ON THE CORNER OF A PIECE OF FURNITURE]}\n",
      "{'sc': [HITTING HER HEAD ON A WINDOW SILL]}\n",
      "{'sc': [HITTING HEAD AGAINST CEMENT STAIRS]}\n",
      "{'sc': [STRUCK HER ELBOW ON A PIECE OF FURNITURE]}\n",
      "{'sc': [HIT A CHAIR WITH HIS RIBS AS HE WAS FALLING]}\n",
      "{'sc': [AGAINST RAILING HITTING CHEST]}\n",
      "{'sc': [HIT HIS HEAD ON A BUCKET]}\n",
      "{'sc': [STRIKING HEAD ONTO THE MATTRESS]}\n",
      "{'sc': [HIT FACE ON END TABLE]}\n",
      "{'sc': [HITTING RIGHT SID OF HER HEAD AGAINST THE WALL]}\n",
      "{'sc': [SCRAPED THE BACK OF HIS HAND  ON THE DOOR FRAME AS HE FELL]}\n",
      "{'sc': [HIT HIS NOSE ON THE TABLE TOP]}\n",
      "{'sc': [INTO THE WALL]}\n",
      "{'sc': [HIT HEAD AGAINST BATHROOM WALL]}\n",
      "{'sc': [HITTING HEAD ON DRESSER]}\n",
      "{'sc': [HITTING HEAD ON MIRROR]}\n",
      "{'sc': [HIT UPPER BACK ON A BUCKET]}\n",
      "{'sc': [FELL INTO HIS WINDOW]}\n",
      "{'sc': [HITTING HEAD TO DOORKNOB]}\n",
      "{'sc': [HIT FOREHEAD ON DESK]}\n",
      "{'sc': [STRIKING HER BACK ON THE BATHROOM DOOR]}\n",
      "{'sc': [STRIKING THE WALL]}\n",
      "{'sc': [HIT HEAD ON TOILET]}\n",
      "{'sc': [HIT HEAD ON GLASS WALL]}\n",
      "{'sc': [FELL AGAINST A WALL]}\n",
      "{'sc': [HITTING ABDOMEN AGAINST CABINET HANDLE]}\n",
      "{'sc': [FALL AGAINST DOOR]}\n",
      "{'sc': [HIT HEAD ON TOILET]}\n",
      "{'sc': [STRUCK THE LEFT TEMPORAL ASPECT OF HER HEAD ON A CABINET]}\n",
      "{'sc': [FALL AGAINST A PALLET]}\n",
      "{'sc': [HIT BRIDGE OF NOSE ON TOWEL RACK]}\n",
      "{'sc': [LANDED ON ROCK]}\n",
      "{'sc': [FALL AGAINST BED]}\n",
      "{'sc': [STRIKING CHEST ONTO THE SINK]}\n",
      "{'sc': [STRIKING HEAD ON A CABINET]}\n",
      "{'sc': [STRIKING BACK ON RAILING]}\n",
      "{'sc': [HIT TOILET]}\n",
      "{'sc': [HITTING HEAD ONTO A DOOR]}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "from spacy.tokens import Span\n",
    "# spancat = nlp.add_pipe(\"spancat_singlelabel\")\n",
    "\n",
    "docs = []\n",
    "for k in keys_list:\n",
    "    # Do something with the doc here\n",
    "    temp_dict = data[k]\n",
    "    doc = nlp(k)\n",
    "    # span_list = []\n",
    "    for span_text, label in temp_dict.items():\n",
    "        if label in ['SO']:\n",
    "            span_start_char = k.find(span_text)\n",
    "            span_end_char = span_start_char + len(span_text)\n",
    "\n",
    "            # Finding the start and end tokens using character offsets\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for token in doc:\n",
    "                if token.idx == span_start_char:\n",
    "                    start_token = token.i\n",
    "                if token.idx + len(token.text) == span_end_char:\n",
    "                    end_token = token.i\n",
    "                    break\n",
    "\n",
    "            if start_token is not None and end_token is not None:\n",
    "                temp_start = start_token\n",
    "                temp_end = end_token + 1\n",
    "                temp_label = label\n",
    "            \n",
    "        \n",
    "                doc.spans[\"sc\"] = [Span(doc, float(temp_start), float(temp_end), temp_label)]\n",
    "                print(doc.spans)\n",
    "    \n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "670d4341-33d2-4639-8c3e-3341137a27e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2b248-4078-413a-9622-58674b528e7c",
   "metadata": {},
   "source": [
    "python -m spacy init config ./config.cfg --lang en --pipeline SpanCategorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08dec8e9-3243-4929-af99-da59854c1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "350d5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin = DocBin(docs=docs[0:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1fa81e1-08f2-41ae-ae6f-d0d2787322b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin.to_disk(\"./train_practice.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f534ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin = DocBin({},False,docs[150:])\n",
    "doc_bin.to_disk(\"./dev_practice.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e220f29-7abc-44bf-8a99-e4a017f84e01",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "260f2df3-c0da-4f9a-ae84-c4dbea3bc93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"/Users/wendyphillips/Documents/Computing/WendysPython/Falling/outputs2/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c6cc55b-d2ee-474e-8097-48c2aca45b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"85YOF WITH HEAD INJURY S/P FALL AND HITTING HEAD ON WALL DX: CLOSED HEAD INJURY AND SCALP CONTUSION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6da730d-f830-4864-bc03-9343182c11ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HITTING HEAD ON WALL]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.spans[\"sc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cf950fb-98d6-4410-86ba-08dd02939886",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO 9 13 SMASHING HEAD ON DRESSER\n"
     ]
    }
   ],
   "source": [
    "for span in doc.spans[\"sc\"]:\n",
    "    print(span.label_, span.start, span.end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ffa9794-24b6-46b4-bce4-dcc976b099b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_sample_sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrandom_sample_sub\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnarrative\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(text)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mspans[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_sample_sub' is not defined"
     ]
    }
   ],
   "source": [
    "for text in random_sample_sub['narrative']:\n",
    "    doc = nlp(text)\n",
    "    for span in doc.spans[\"sc\"]:\n",
    "        print(span.label_, span.start, span.end, span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e981a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
