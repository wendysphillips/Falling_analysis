{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c3d52-681a-4702-946a-58424d90ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb2f37",
   "metadata": {},
   "source": [
    "### load variable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"variable_mapping.json\").open(\"r\") as f:\n",
    "    mapping = json.load(f, parse_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the encoded values in the mapping to integers since they get read in as strings\n",
    "for c in mapping.keys():\n",
    "    mapping[c] = {int(k): v for k, v in mapping[c].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dbb9d",
   "metadata": {},
   "source": [
    "### load primary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fddc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"corrected_narrative_primary2.csv\",\n",
    "    # set columns that can be null to nullable ints\n",
    "    dtype={\"body_part_2\": \"Int64\", \"diagnosis_2\": \"Int64\"},\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e80fbe",
   "metadata": {},
   "source": [
    "### replace numeric values with corresponding strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df = df.copy()\n",
    "\n",
    "for col in mapping.keys():\n",
    "    decoded_df[col] = decoded_df[col].map(mapping[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c7fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79536b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure mappings were applied correctly by checking that the number of missing values did not change\n",
    "assert (decoded_df.isnull().sum() == df.isnull().sum()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62524b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.to_csv(\"decoded_primary_data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ad37b-9614-437b-aac7-64aa5e39e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = decoded_df.sample(n=5000, replace=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683c71b-ad2f-45b7-899d-3117140c3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_sub = random_sample.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447cd5e-6798-43ff-9250-cd90a6d17860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b54147-4454-4311-bb57-1850a3f1871e",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c0b39-9bfb-4453-a9f7-6742d023f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18501e0d-7920-492b-a259-fd0bc34bad42",
   "metadata": {},
   "source": [
    "# My Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91e26a-632b-4f0a-bc62-a4ab88f338b5",
   "metadata": {},
   "source": [
    "Corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628b143-9f57-4b01-9e39-0846c0f2dd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fall_in = pd.read_csv('double_corrected_narrative_primary3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be50d35-1c6b-47c3-b486-478fd58a0c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fall_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ac075",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fall_in['key_entry'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall = fall_in.iloc[:,1:5]\n",
    "fall.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall.drop_duplicates(inplace=True)\n",
    "len(fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87766829",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_nas = fall[fall['span'].isna()]\n",
    "fall_nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72117b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fall_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89708b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = fall.label.unique()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only the labels you want to build model with\n",
    "# note: this chunk of code will eliminate a lot of useful texts without these labels\n",
    "#    it would be good to modify it so that it doesn't\n",
    "labels_to_use = ['SO', 'WT', 'SF', 'TRS', 'STR', 'SU', 'CHR', 'OBJ', 'SHW', 'RCH', 'LAD', 'WF']\n",
    "fall_sub = fall[fall['label'].isin(labels_to_use)]\n",
    "len(fall_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back in the NA rows\n",
    "fall_all = pd.concat((fall_sub, fall_nas))\n",
    "fall_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3114563",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_all_random = fall_all.sample(n=len(fall_all), replace=False, random_state=99)\n",
    "fall_all_random.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4489540-39a1-4ac2-90a9-b823642f9c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_list = fall_all_random.key_entry.unique()\n",
    "len(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_all_random[fall_all_random.key_entry == key_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aca9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "# special_case = [{Token.ORTH: \"CLOSED-HEAD\"}]\n",
    "# nlp.tokenizer.add_special_case(\"CLOSED-HEAD\", special_case)\n",
    "\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# keeping span token lengths to appropriately set config\n",
    "token_lengths = []\n",
    "label_list = []\n",
    "\n",
    "docs=[] # this will hold the processed strings and spans\n",
    "for k in key_list:\n",
    "    print(k)\n",
    "    doc = nlp(k)\n",
    "    temp_df = fall_all_random[fall_all_random.key_entry == k]\n",
    "\n",
    "    if len(temp_df)==1:    \n",
    "        if pd.isna(temp_df.iloc[0,2]):\n",
    "            doc.spans[\"sc\"] = []\n",
    "            docs.append(doc)\n",
    "        else:     \n",
    "            span_text = temp_df.iloc[0,1]\n",
    "            temp_label = temp_df.iloc[0,2]       \n",
    "            span_start_char = k.find(span_text)\n",
    "            span_end_char = span_start_char + len(span_text)\n",
    "    \n",
    "            # Finding the start and end tokens using character offsets\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for token in doc:\n",
    "                if token.idx == span_start_char:\n",
    "                     start_token = token.i\n",
    "                if token.idx + len(token.text) == span_end_char:\n",
    "                    end_token = token.i\n",
    "                    break\n",
    "            if start_token is not None and end_token is not None:\n",
    "                temp_start = start_token\n",
    "                temp_end = end_token + 1\n",
    "                doc.spans[\"sc\"] = [Span(doc, temp_start, temp_end, temp_label)]\n",
    "                docs.append(doc)\n",
    "                token_lengths.append(temp_end - temp_start)\n",
    "                label_list.append(temp_label)\n",
    "            else:\n",
    "                print(k, \"span=\", span_text,\"couldn't find tokens\")\n",
    "    else:\n",
    "        print(\"temp_df has length > 1\")\n",
    "        span_list = []\n",
    "        for ent in range(len(temp_df)):\n",
    "            span_text = temp_df.iloc[ent,1]\n",
    "            temp_label = temp_df.iloc[ent,2]\n",
    "            span_start_char = k.find(span_text)\n",
    "            span_end_char = span_start_char + len(span_text)\n",
    "            print(span_start_char, span_end_char)\n",
    "\n",
    "            # Finding the start and end tokens using character offsets\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for token in doc:\n",
    "                if token.idx == span_start_char:\n",
    "                     start_token = token.i\n",
    "                if token.idx + len(token.text) == span_end_char:\n",
    "                    end_token = token.i\n",
    "                    break\n",
    "            if start_token is not None and end_token is not None:\n",
    "                temp_start = start_token\n",
    "                temp_end = end_token + 1             \n",
    "                span_list.append(Span(doc, temp_start, temp_end, temp_label))\n",
    "                token_lengths.append(temp_end - temp_start)\n",
    "                label_list.append(temp_label)\n",
    "            else:\n",
    "                print(k, \"span=\",span_text, \"couldn't find tokens\")\n",
    "        \n",
    "        doc.spans[\"sc\"] = span_list\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs[0:5]:\n",
    "    print(doc, doc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(token_lengths), np.max(token_lengths), np.median(token_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a50f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(token_lengths, q =[0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598401fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[799]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888d041",
   "metadata": {},
   "source": [
    "Make training and test sets with the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dec8e9-3243-4929-af99-da59854c1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa81e1-08f2-41ae-ae6f-d0d2787322b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin = DocBin(docs=docs[0:800])\n",
    "doc_bin.to_disk(\"./train_231001_1117.spacy\")\n",
    "\n",
    "doc_bin = DocBin(docs=docs[800:])\n",
    "doc_bin.to_disk(\"./dev_231001_1117.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2b248-4078-413a-9622-58674b528e7c",
   "metadata": {},
   "source": [
    "python -m spacy init config ./config.cfg --lang en --pipeline spancat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e220f29-7abc-44bf-8a99-e4a017f84e01",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f2df3-c0da-4f9a-ae84-c4dbea3bc93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp_spancat = spacy.load(\"outputs_231001_1117/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spancat.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cc55b-d2ee-474e-8097-48c2aca45b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_text = random_sample_sub.iloc[2102,1]\n",
    "doc = nlp_spancat(test_text)\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf950fb-98d6-4410-86ba-08dd02939886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for span in doc.spans[\"sc\"]:\n",
    "    print(span.label_, span.start, span.end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb839128",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Test model on a subset of the samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d8a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_sub2 = random_sample_sub.iloc[2000:3500,]\n",
    "\n",
    "# Create an empty DataFrame with column names\n",
    "output_df = pd.DataFrame(columns=['text', 'span_label', 'span_text'])\n",
    "\n",
    "for text in random_sample_sub2['narrative']:\n",
    "    doc = nlp_spancat(text)\n",
    "    \n",
    "    if len(doc.spans[\"sc\"]) == 0:\n",
    "        df2 = pd.DataFrame([[text, \"NA\", \"NA\"]], columns=['text', 'span_label', 'span_text'])\n",
    "        # Append the new row to the DataFrame\n",
    "        output_df = pd.concat([output_df, df2])\n",
    "    else:\n",
    "        for span in doc.spans[\"sc\"]:\n",
    "        # Create a new row as a dictionary\n",
    "        \n",
    "            df2 = pd.DataFrame([[text, span.label_, span.text]], columns=['text', 'span_label', 'span_text'])\n",
    "            # Append the new row to the DataFrame\n",
    "            output_df = pd.concat([output_df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"predictions_strikes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30973c8",
   "metadata": {},
   "source": [
    "## Run model on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46699bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with column names\n",
    "output_df = pd.DataFrame(columns=['cpsc_case_number','text', 'span_label', 'span_text'])\n",
    "\n",
    "for row in decoded_df.iloc[:,0:2].iterrows():\n",
    "    cpsc = (row[1]['cpsc_case_number'])\n",
    "    text = (row[1]['narrative'])\n",
    "    doc = nlp_spancat(text)\n",
    "\n",
    "    \n",
    "    if len(doc.spans[\"sc\"]) == 0:\n",
    "        df2 = pd.DataFrame([[cpsc,text, \"NA\", \"NA\"]], columns=['cpsc_case_number','text', 'span_text', 'span_label'])\n",
    "        # Append the new row to the DataFrame\n",
    "        output_df = pd.concat([output_df, df2])\n",
    "    else:\n",
    "        for span in doc.spans[\"sc\"]:\n",
    "        # Create a new row as a dictionary\n",
    "        \n",
    "            df2 = pd.DataFrame([[cpsc,text, span.label_, span.text]], columns=['cpsc_case_number','text', 'span_label', 'span_text'])\n",
    "            # Append the new row to the DataFrame\n",
    "            output_df = pd.concat([output_df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82780459",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"predictions_full_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "def tuple_aggregator(series):\n",
    "    return tuple(series)\n",
    "\n",
    "pivot_output_df = output_df.pivot_table(index=['cpsc_case_number', 'text'], columns='span_label', values='span_text', aggfunc=tuple_aggregator).reset_index()\n",
    "pivot_output_df.columns.name = None \n",
    "pivot_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame\n",
    "binary_df = pivot_output_df.copy()\n",
    "\n",
    "# Update the DataFrame to have 0 for NaN and 1 for actual values\n",
    "# We're excluding the first two columns ('A' and 'B') as they are index columns\n",
    "binary_df.iloc[:, 2:] = binary_df.iloc[:, 2:].map(lambda x: 0 if x == 'NA' or pd.isna(x) else 1)\n",
    "binary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af359d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.merge(binary_df, decoded_df, how=\"left\", on=\"cpsc_case_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e752e",
   "metadata": {},
   "source": [
    "Gather rows for specific strike types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ec765",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_object = combo_df[(combo_df['SO']==1) & (combo_df['SF']!=1) & (combo_df['SU']!=1)]\n",
    "struck_floor = combo_df[(combo_df['SO']!=1) & (combo_df['SF']==1) & (combo_df['SU']!=1)]\n",
    "struck_unknown = combo_df[(combo_df['SO']!=1) & (combo_df['SF']!=1) & (combo_df['SU']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec486f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(struck_floor), len(struck_object), len(struck_unknown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4bebb",
   "metadata": {},
   "source": [
    "Look at frequencies of dispositon and diagnosis by strike type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_floor['disposition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3202cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_unknown['disposition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_object['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_floor['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_unknown['diagnosis'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
