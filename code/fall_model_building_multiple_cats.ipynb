{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48508747",
   "metadata": {},
   "source": [
    "# Investigating clinical notes regarding falls in older adults\n",
    "Author: Wendy Phillips\n",
    "\n",
    "## Problem statement\n",
    "\n",
    "Falls in older adults are frequent and can have major health impacts.\n",
    "\n",
    "## Data description\n",
    "\n",
    "Clinical notes and metadata associated with 111,000 visits to the doctor were analyzed.\n",
    "\n",
    "## Analytic approach\n",
    "\n",
    "Natural Language Processing (NLP) was applied to the clinical notes to extract informative content. Specifically, the NLP tool spaCy was used to build a model that could identify and label specific spans of the text that held information of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c3d52-681a-4702-946a-58424d90ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from spacy.tokens import Span\n",
    "from spacy.tokens import DocBin\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb2f37",
   "metadata": {},
   "source": [
    "### load variable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"primary_data/variable_mapping.json\").open(\"r\") as f:\n",
    "    mapping = json.load(f, parse_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the encoded values in the mapping to integers since they get read in as strings\n",
    "for c in mapping.keys():\n",
    "    mapping[c] = {int(k): v for k, v in mapping[c].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dbb9d",
   "metadata": {},
   "source": [
    "### load primary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fddc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"primary_data/primary_data.csv\",\n",
    "    # set columns that can be null to nullable ints\n",
    "    dtype={\"body_part_2\": \"Int64\", \"diagnosis_2\": \"Int64\"},\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e817ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81727a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_terms = {\n",
    "    \"&\": \"and\",\n",
    "    \"***\": \"\",\n",
    "    \">>\": \"clinical diagnosis\",\n",
    "    \"@\": \"at\",\n",
    "    \"+\": \"with\",\n",
    "    \"?\": \"unknown if\",\n",
    "    \"abd\": \"abdomen\",\n",
    "    \"af\": \"accidental fall\",\n",
    "    \"afib\": \"atrial fibrillation\",\n",
    "    \"alf\": \"assisted living facility\",\n",
    "    \"aki\": \"acute kidney injury\",\n",
    "    \"am\": \"morning\",\n",
    "    \"ams\": \"altered mental status\",\n",
    "    \"bac\": \"blood alcohol content\",\n",
    "    \"biba\": \"brought in by ambulance\",\n",
    "    \"bwd\": \"backwards\",\n",
    "    \"c/o\": \"complains of\",\n",
    "    \"chi\": \"closed-head injury\",\n",
    "    \"clsd\": \"closed\",\n",
    "    \"cpk\": \"creatine phosphokinase\",\n",
    "    \"cva\": \"cerebral vascular accident\",\n",
    "    \"dn\": \"down\",\n",
    "    \"dtr\": \"daughter\",\n",
    "    \"dx\": \"clinical diagnosis\",\n",
    "    \"ecf\": \"extended care facility\",\n",
    "    \"er\": \"emergency room\",\n",
    "    \"etoh\": \"ethyl alcohol\",\n",
    "    \"eval\": \"evaluation\",\n",
    "    \"fd\": \"found\",\n",
    "    \"ft\": \"foot\",\n",
    "    \"fx\": \"fracture\",\n",
    "    \"fxs\": \"fractures\",\n",
    "    \"fwd\": \"forwards\",\n",
    "    \"glf\": \"ground level fall\",\n",
    "    \"h/o\": \"history of\",\n",
    "    \"hr\": \"hours\",\n",
    "    \"htn\": \"hypertension\",\n",
    "    \"hx\": \"history of\",\n",
    "    \"inj\": \"injury\",\n",
    "    \"inr\": \"international normalized ratio\",\n",
    "    \"intox\": \"intoxication\",\n",
    "    \"lac\": \"laceration\",\n",
    "    \"loc\": \"loss of consciousness\",\n",
    "    \"lt\": \"left\",\n",
    "    \"mech\": \"mechanical\",\n",
    "    \"mult\": \"multiple\",\n",
    "    \"n h \": \"nursing home\",\n",
    "    \"nh\": \"nursing home\",\n",
    "    \"p/w\": \"presents with\",\n",
    "    \"pm\": \"afternoon\",\n",
    "    \"pt\": \"patient\",\n",
    "    \"pta\": \"prior to arrival\",\n",
    "    \"pts\": \"patient's\",\n",
    "    \"px\": \"physical examination\", # not \"procedure\",\n",
    "    \"r/o\": \"rules out\",\n",
    "    \"rt\": \"right\",\n",
    "    \"s/p\": \"after\",\n",
    "    \"sah\": \"subarachnoid hemorrhage\",\n",
    "    \"sdh\": \"acute subdural hematoma\",\n",
    "    \"sts\": \"sit to stand\",\n",
    "    \"tr\": \"trauma\",\n",
    "    \"uti\": \"urinary tract infection\",\n",
    "    \"unwit'd\": \"unwitnessed\",\n",
    "    \"w/o\": \"without\",\n",
    "    \"w/\": \"with\",\n",
    "    \"wks\": \"weeks\"\n",
    "}\n",
    "\n",
    "def add_space_after(text, target=\",\"):\n",
    "    replaced_text = re.sub(r'({})(\\S)'.format(re.escape(target)), r'{} \\2'.format(target),text)\n",
    "    return replaced_text\n",
    "\n",
    "def add_space_before(text, target=\",\"):\n",
    "    replaced_text = re.sub(r'(\\S)({})'.format(re.escape(target)), r'\\1 {}'.format(target), text)\n",
    "    return replaced_text\n",
    "\n",
    "# cleanning\n",
    "def clean_narrative(text):\n",
    "    # lowercase everything\n",
    "    if pd.isna(text):\n",
    "        return \"NA\"\n",
    "    else:     \n",
    "        text = text.lower()\n",
    "        \n",
    "        # unglue DX\n",
    "        regex_dx = r\"([ˆ\\W]*(dx)[ˆ\\W]*)\"\n",
    "        text = re.sub(regex_dx, r\". dx: \", text)\n",
    "    \n",
    "        # remove age and sex identifications\n",
    "        ## regex to capture age and sex (not perfect but captures almost all of the cases)\n",
    "        regex_age_sex = r\"(\\d+)\\s*?(yof|yf|yo\\s*female|yo\\s*f|yom|ym|yo\\s*male|yo\\s*m)\"\n",
    "        age_sex_match = re.search(regex_age_sex, text)\n",
    "    \n",
    "        ## format age and sex\n",
    "        if age_sex_match:\n",
    "            age = age_sex_match.group(1)\n",
    "            sex = age_sex_match.group(2)\n",
    "            \n",
    "            # probably not best practice but it works with this data\n",
    "            if \"f\" in sex:\n",
    "                #text = text.replace(age_sex_match.group(0), f\"{age} years old female\")\n",
    "                text = text.replace(age_sex_match.group(0), f\"patient\")\n",
    "            elif \"m\" in sex:\n",
    "                #text = text.replace(age_sex_match.group(0), f\"{age} years old male\")\n",
    "                text = text.replace(age_sex_match.group(0), f\"patient\")\n",
    "                \n",
    "        text = add_space_after(text, target=\",\") \n",
    "        text = add_space_after(text, target=\";\") \n",
    "        text = add_space_after(text, target=\":\") \n",
    "        text = add_space_before(text, target=\"--\")  \n",
    "        text = add_space_after(text, target=\"--\")\n",
    "        text = re.sub(\"-\", \" \", text)\n",
    "        text = re.sub(r\"([0-9]+(\\.[0-9]+)?)\",r\" \\1 \", text).strip()\n",
    "        text = re.sub(\"\\.\", \" \", text)\n",
    "        \n",
    "        # The below two are separated from the dictionary because of the '&' character conflict\n",
    "        #   with the translate medical terms section use of '&'\n",
    "        text = re.sub(\"t'd&f\", \"tripped and fell\", text)\n",
    "        text = re.sub(\"s'd&f\", \"slipped and fell\",text)     \n",
    "    \n",
    "        \n",
    "        # translate medical terms\n",
    "        for term, replacement in medical_terms.items():\n",
    "            if term == \"@\" or term == \">>\" or term == \"&\" or term == \"***\" or term == \"+\" or term == \"?\":\n",
    "                pattern = fr\"({re.escape(term)})\"\n",
    "                text = re.sub(pattern, f\" {replacement} \", text) # force spaces around replacement\n",
    "                \n",
    "            else:\n",
    "                pattern = fr\"(?<!-)\\b({re.escape(term)})\\b(?!-)\"\n",
    "                text = re.sub(pattern, replacement, text)\n",
    "                            \n",
    "        # This done after translate medical terms because some use a '/'\n",
    "        text = add_space_before(text, target=\"/\")  \n",
    "        text = add_space_after(text, target=\"/\")\n",
    "        \n",
    "        # remove extra white spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "        return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '72 YOF SLIPPED AND FELL ON THE FLOOR THIS AM>>L-3, L-4 FRACTURE, +LOC, RT RIB FRACTURES X 3.'\n",
    "print(\"Original text:\", text)\n",
    "print(\"Clean text:\", clean_narrative(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_narratives = df.iloc[:, 0:2]\n",
    "df_narratives['narrative'] = df_narratives['narrative'].apply(lambda x: clean_narrative(x))\n",
    "\n",
    "# Rename original narrative column\n",
    "df_nn = df.rename(columns={\"narrative\": \"narrative_original\"})\n",
    "\n",
    "df_final = pd.merge(df_narratives, df_nn, on=\"cpsc_case_number\", how=\"left\")\n",
    "\n",
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3040bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"corrected_narrative_primary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e80fbe",
   "metadata": {},
   "source": [
    "### replace numeric values with corresponding strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df = df_final.copy()\n",
    "\n",
    "for col in mapping.keys():\n",
    "    decoded_df[col] = decoded_df[col].map(mapping[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ce747",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79536b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure mappings were applied correctly by checking that the number of missing values did not change\n",
    "assert (decoded_df.isnull().sum() == df_final.isnull().sum()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4ad78",
   "metadata": {},
   "source": [
    "Add a column that reveals how many characters are in each narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404015ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df['narrative_characters'] = decoded_df['narrative'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(decoded_df['narrative_characters'])\n",
    "# plt.savefig(\"Narrative_character_count.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23691253",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(decoded_df, x = 'narrative_characters', hue = 'sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed477fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(decoded_df, x = 'narrative_characters', hue = 'sex', kind = 'kde', fill = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb50a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.to_csv(\"decoded_primary_data_with_char_lens.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2761150",
   "metadata": {},
   "source": [
    "Take a random sample for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ad37b-9614-437b-aac7-64aa5e39e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = decoded_df.sample(n=5000, replace=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683c71b-ad2f-45b7-899d-3117140c3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_sub = random_sample.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447cd5e-6798-43ff-9250-cd90a6d17860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_sample_sub.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18501e0d-7920-492b-a259-fd0bc34bad42",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91e26a-632b-4f0a-bc62-a4ab88f338b5",
   "metadata": {},
   "source": [
    "Import semi-manually labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628b143-9f57-4b01-9e39-0846c0f2dd48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeled_sets = pd.read_csv('secondary_data/labeled_training_data.csv')\n",
    "labeled_sets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cab241",
   "metadata": {},
   "source": [
    "Check how long the imported data frame is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ca817",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labeled_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27894130",
   "metadata": {},
   "source": [
    "Check how many unique cases are contained in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4489540-39a1-4ac2-90a9-b823642f9c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_list = labeled_sets.cpsc_case_number.unique()\n",
    "len(key_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d1fdd",
   "metadata": {},
   "source": [
    "Randomly shuffle the key list in case there is some bias in the order of the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34803b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "np.random.shuffle(key_list, )\n",
    "key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aca9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "# special_case = [{Token.ORTH: \"CLOSED-HEAD\"}]\n",
    "# nlp.tokenizer.add_special_case(\"CLOSED-HEAD\", special_case)\n",
    "\n",
    "# keeping span token lengths to appropriately set config\n",
    "token_lengths = []\n",
    "label_list = []\n",
    "\n",
    "docs=[] # this will hold the processed strings and spans\n",
    "\n",
    "for case in key_list:\n",
    "    # print(case)\n",
    "    # print(k) # uncomment for troubleshooting\n",
    "\n",
    "    temp_df = labeled_sets[labeled_sets.cpsc_case_number == case]\n",
    "    nar = temp_df.iloc[0,1]\n",
    "        \n",
    "    doc = nlp(nar)\n",
    "    \n",
    "    if len(temp_df)==1:    \n",
    "        if pd.isna(temp_df.iloc[0,2]):\n",
    "            print(\"this entry has no label\")\n",
    "            doc.spans[\"sc\"] = []\n",
    "            docs.append(doc)\n",
    "        else:     \n",
    "            span_text = temp_df.iloc[0,2]\n",
    "            temp_label = temp_df.iloc[0,3]   \n",
    "            span_start_char = nar.find(span_text)\n",
    "            span_end_char = span_start_char + len(span_text)\n",
    "            \n",
    "            # Finding the start and end tokens using character offsets\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for token in doc:\n",
    "                if token.idx == span_start_char:\n",
    "                     start_token = token.i\n",
    "                if token.idx + len(token.text) == span_end_char:\n",
    "                    end_token = token.i\n",
    "                    break\n",
    "                    \n",
    "            if start_token is not None and end_token is not None:\n",
    "                temp_start = start_token\n",
    "                temp_end = end_token + 1\n",
    "                \n",
    "                doc.spans[\"sc\"] = [Span(doc, temp_start, temp_end, temp_label)]\n",
    "                \n",
    "                token_lengths.append(temp_end - temp_start)\n",
    "                label_list.append(temp_label)\n",
    "            \n",
    "                docs.append(doc)\n",
    "            else:\n",
    "                print(nar, \"span=\", span_text,\"couldn't find tokens\")\n",
    "    else:\n",
    "        print(\"temp_df has length > 1\")\n",
    "        span_list = []\n",
    "        for ent in range(len(temp_df)):\n",
    "            span_text = temp_df.iloc[ent,2]\n",
    "            temp_label = temp_df.iloc[ent,3]\n",
    "            span_start_char = nar.find(span_text)\n",
    "            span_end_char = span_start_char + len(span_text)\n",
    "            # print(span_start_char, span_end_char)\n",
    "\n",
    "            # Finding the start and end tokens using character offsets\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for token in doc:\n",
    "                if token.idx == span_start_char:\n",
    "                     start_token = token.i\n",
    "                if token.idx + len(token.text) == span_end_char:\n",
    "                    end_token = token.i\n",
    "                    break\n",
    "            if start_token is not None and end_token is not None:\n",
    "                temp_start = start_token\n",
    "                temp_end = end_token + 1             \n",
    "                span_list.append(Span(doc, temp_start, temp_end, temp_label))\n",
    "                token_lengths.append(temp_end - temp_start)\n",
    "                label_list.append(temp_label)\n",
    "            else:\n",
    "                print(nar, \"span=\",span_text, \"couldn't find tokens\")\n",
    "        \n",
    "        doc.spans[\"sc\"] = span_list\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ac107",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs[0:5]:\n",
    "    print(doc, doc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4ee0d",
   "metadata": {},
   "source": [
    "Check on length of tokens in spans to set appropriate parameters in training config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(token_lengths), np.max(token_lengths), np.median(token_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a50f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.quantile(token_lengths, q =[0.05,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b9173",
   "metadata": {},
   "source": [
    "Want to split the data into train and test such that a single case is not split between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c48328",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163be711",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888d041",
   "metadata": {},
   "source": [
    "Make training and test sets with the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa81e1-08f2-41ae-ae6f-d0d2787322b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin = DocBin(docs=docs[0:1101])\n",
    "doc_bin.to_disk(\"./train_falling.spacy\")\n",
    "\n",
    "doc_bin = DocBin(docs=docs[1101:])\n",
    "doc_bin.to_disk(\"./dev_falling.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ef9b8",
   "metadata": {},
   "source": [
    "Initialize the training config file. This will get some manual adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init config configs/config_spancat_singlelabel.cfg --lang en --pipeline spancat_singlelabel --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a21b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train configs/config_HP4.cfg --paths.train train_falling.spacy --paths.dev dev_falling.spacy --training.eval_frequency 100  --system.seed 99 --output spacy_falling_model4/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e220f29-7abc-44bf-8a99-e4a017f84e01",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f2df3-c0da-4f9a-ae84-c4dbea3bc93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp_spancat = spacy.load(\"spacy_falling_model/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spancat.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8077b59",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Test model on a subset of the samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d8a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cpsc_case_number','text', 'span_text',  'span_label', ]\n",
    "output_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "for row in random_sample_sub.iloc[1000:1050:,0:2].iterrows():\n",
    "    cpsc = (row[1]['cpsc_case_number'])\n",
    "    text = (row[1]['narrative'])\n",
    "    doc = nlp_spancat(text)\n",
    "\n",
    "    \n",
    "    if len(doc.spans[\"sc\"]) == 0:\n",
    "        df2 = pd.DataFrame([[cpsc,text, \"NA\", \"NA\"]], columns= cols)\n",
    "        # Append the new row to the DataFrame\n",
    "        output_df = pd.concat([output_df, df2])\n",
    "    else:\n",
    "        for span in doc.spans[\"sc\"]:\n",
    "        # Create a new row as a dictionary\n",
    "        \n",
    "            df2 = pd.DataFrame([[cpsc,text, span.text, span.label_,]], columns=cols)\n",
    "            # Append the new row to the DataFrame\n",
    "            output_df = pd.concat([output_df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a98a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0347ff6",
   "metadata": {},
   "source": [
    "## Run model on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df.iloc[0:3:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dab1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in decoded_df.iloc[0:12:,0:2].iterrows():\n",
    "    cpsc = (row[1]['cpsc_case_number'])\n",
    "    text = (row[1]['narrative'])\n",
    "    doc = nlp_spancat(text)\n",
    "    print(doc.spans[\"sc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with column names\n",
    "cols = ['cpsc_case_number','text', 'span_text', 'span_label']\n",
    "output_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "for row in decoded_df.iloc[:,0:2].iterrows():\n",
    "    cpsc = (row[1]['cpsc_case_number'])\n",
    "    text = (row[1]['narrative'])\n",
    "    doc = nlp_spancat(text)\n",
    "\n",
    "    \n",
    "    if len(doc.spans[\"sc\"]) == 0:\n",
    "        df2 = pd.DataFrame([[cpsc, text, \"NA\", \"NA\"]], columns=cols)\n",
    "        # Append the new row to the DataFrame\n",
    "        output_df = pd.concat([output_df, df2])\n",
    "    else:\n",
    "        for span in doc.spans[\"sc\"]:\n",
    "        # Create a new row as a dictionary\n",
    "        \n",
    "            df2 = pd.DataFrame([[cpsc, text, span.text, span.label_]], columns=cols)\n",
    "            # Append the new row to the DataFrame\n",
    "            output_df = pd.concat([output_df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99898cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ed92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"predictions_falling_full_set5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "def tuple_aggregator(series):\n",
    "    return tuple(series)\n",
    "\n",
    "pivot_output_df = output_df.pivot_table(index=['cpsc_case_number', 'text'], columns='span_label', values='span_text', aggfunc=tuple_aggregator).reset_index()\n",
    "pivot_output_df.columns.name = None \n",
    "pivot_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eda525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame\n",
    "binary_df = pivot_output_df.copy()\n",
    "\n",
    "# Update the DataFrame to have 0 for NaN and 1 for actual values\n",
    "# We're excluding the first two columns ('A' and 'B') as they are index columns\n",
    "binary_df.iloc[:, 2:] = binary_df.iloc[:, 2:].map(lambda x: 0 if x == 'NA' or pd.isna(x) else 1)\n",
    "binary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df.to_csv(\"predictions_full_set_binary_231003.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.merge(binary_df, decoded_df, how=\"left\", on=\"cpsc_case_number\")\n",
    "combo_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252c6d0",
   "metadata": {},
   "source": [
    "### Clean labels for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26607546",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df['diagnosis'] = combo_df['diagnosis'].str.replace(r'\\d+ - ', '', regex=True)\n",
    "print(combo_df['diagnosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df['diagnosis']= combo_df['diagnosis'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df['disposition'] = combo_df['disposition'].str.replace(r'\\d+ - ', '', regex=True)\n",
    "print(combo_df['disposition'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a507a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'TREATED AND ADMITTED/HOSPITALIZED': 'Admitted', \n",
    "                 'TREATED/EXAMINED AND RELEASED': 'Released', \n",
    "                 'HELD FOR OBSERVATION': 'Held', \n",
    "                 'TREATED AND TRANSFERRED': 'Transferred',  \n",
    "                 'LEFT WITHOUT BEING SEEN': 'Unseen', }\n",
    "combo_df['disposition'] = combo_df['disposition'].map(label_mapping)\n",
    "print(combo_df['disposition'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6398bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(combo_df, x = 'narrative_characters', hue = 'disposition', kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e5e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"predictions_falling_full_set5.csv\")\n",
    "output_df = temp_df.iloc[:,1:5]\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ddd505",
   "metadata": {},
   "source": [
    "### Words within labeled spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO_entries = output_df[output_df['span_label'] == 'SO']\n",
    "len(SO_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2838d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa28064",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_entries = output_df[output_df['span_label'] == 'OBJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5527e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_remove_OBJ = ['TRIPPED', 'OVER', 'A', 'AN','ON', 'THE', 'HER', \n",
    "                   'OF', 'HIS', 'TRIPPING', 'FALL', 'FELL', 'SLIPPED', 'OWN', 'FEET']\n",
    "OBJ_words = []\n",
    "for i in range(len(OBJ_entries)):\n",
    "    temp_entry = OBJ_entries.iloc[i,2]\n",
    "    temp_text  = temp_entry.split(' ')\n",
    "    out_temp = list(set(temp_text)-set(list_remove_OBJ))\n",
    "    OBJ_words.append(out_temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_word_counts = collections.Counter(flatten_list(OBJ_words))\n",
    "my_dict = dict(OBJ_word_counts)\n",
    "\n",
    "rows = []\n",
    "for key, value in my_dict.items():\n",
    "    row = {'element': key, 'count': value}\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows).sort_values('count', ascending=False)\n",
    "\n",
    "df.set_index('element', inplace=True)\n",
    "OBJ_plot_subset = df.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = OBJ_plot_subset.plot.barh(width = 0.8)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Object causing fall')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "plt.savefig(\"Object_causing.pdf\", format=\"pdf\", pad_inches = 0.5, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f09e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_remove = ['A', 'HEAD', 'HIT', 'THE', 'ON', 'HITTING', 'STRIKING', \n",
    "               'HER', 'OF', 'AGAINST', 'STRUCK', 'ONTO', 'HIS', 'INTO',\n",
    "              'FACE','BACK', 'SIDE', 'CHEST', 'RIGHT', 'LEFT', 'EDGE', \n",
    "               'FOREHEAD', 'STAND','FRAME', 'AND', 'COFFEE', 'LANDED', 'ARM'\n",
    "              ]\n",
    "SO_words = []\n",
    "for i in range(len(SO_entries)):\n",
    "    temp_entry = SO_entries.iloc[i,2]\n",
    "    temp_text  = temp_entry.split(' ')\n",
    "    out_temp = list(set(temp_text)-set(list_remove))\n",
    "    SO_words.append(out_temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea329167",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "              \n",
    "SO_word_counts = collections.Counter(flatten_list(SO_words))\n",
    "my_dict = dict(SO_word_counts)\n",
    "\n",
    "rows = []\n",
    "for key, value in my_dict.items():\n",
    "    row = {'element': key, 'count': value}\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows).sort_values('count', ascending=False)\n",
    "\n",
    "df.set_index('element', inplace=True)\n",
    "SO_plot_subset = df.head(15)\n",
    "SO_plot_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = SO_plot_subset.plot.barh(width = 0.8)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Object struck')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "plt.savefig(\"Object_struck.pdf\", format=\"pdf\", pad_inches = 0.5, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a1fd1",
   "metadata": {},
   "source": [
    "Gather rows for specific strike types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_involved = combo_df[combo_df['OBJ'] == 1]\n",
    "len(object_involved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_object = combo_df[(combo_df['SO']==1) & (combo_df['SF']!=1) & (combo_df['SU']!=1)]\n",
    "struck_floor = combo_df[(combo_df['SO']!=1) & (combo_df['SF']==1) & (combo_df['SU']!=1)]\n",
    "struck_unknown = combo_df[(combo_df['SO']!=1) & (combo_df['SF']!=1) & (combo_df['SU']==1)]\n",
    "print(len(struck_floor), len(struck_object), len(struck_unknown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96beaac2",
   "metadata": {},
   "source": [
    "Bind the struck object and struck floor sets back together for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185eb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_object = struck_object.assign(struck = 'Object')\n",
    "struck_floor = struck_floor.assign(struck = 'Floor')\n",
    "striking_df = pd.concat([struck_object, struck_floor ], ignore_index=True) \n",
    "striking_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0242d",
   "metadata": {},
   "source": [
    "Plot disposition distribution for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92069aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "strike_disp = striking_df[['disposition', 'struck' ]]\n",
    "strike_disp_counts = strike_disp.groupby(['struck', 'disposition']).size().reset_index(name='count')\n",
    "temp = strike_disp_counts.pivot(columns = 'disposition', index = 'struck', values = 'count' )\n",
    "temp.columns.name=''\n",
    "col_order = ['Released', 'Admitted', 'Held', 'Transferred', 'Unseen']\n",
    "temp2 = temp[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efe619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "#sns.set_palette('colorblind')\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# Convert to relative proportions \n",
    "temp2.apply(lambda x: x*100/sum(x), axis = 1).plot(kind = 'bar', stacked = True, fontsize = 14, edgecolor='none')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2) \n",
    "plt.ylabel(\"Percent\", size = 16)\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(\"Disposition_by_strike.pdf\", format=\"pdf\", pad_inches = 0.5, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b71585",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cols_to_use = ['Internal Injury',\n",
    " 'Fracture',\n",
    " 'Laceration',\n",
    " 'Contusions, Abr.',\n",
    " 'Avulsion',\n",
    " 'Hematoma',\n",
    " 'Concussion',\n",
    " 'Strain, Sprain',\n",
    " 'Dislocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a08450",
   "metadata": {},
   "outputs": [],
   "source": [
    "striking_other = striking_df[striking_df['diagnosis'].isin(diag_cols_to_use) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26242938",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_diag_counts = striking_other.groupby(['struck', 'diagnosis']).size().reset_index(name='count').groupby(['struck']).sum('count')\n",
    "other_diag_counts.reset_index()\n",
    "other_diag_counts.rename(columns = {'count': 'Other'}, inplace = True)\n",
    "other_diag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "strike_diag = striking_df[['diagnosis', 'struck' ]]\n",
    "strike_diag_sub = strike_diag[strike_diag['diagnosis'].isin(diag_cols_to_use)]\n",
    "strike_diag_counts = strike_diag_sub.groupby(['struck', 'diagnosis']).size().reset_index(name='count')\n",
    "temp = strike_diag_counts.pivot(columns = 'diagnosis', index = 'struck', values = 'count' )\n",
    "temp.columns.name=''\n",
    "temp_ordered = temp[diag_cols_to_use]\n",
    "new_df = temp_ordered.merge(other_diag_counts, left_on = 'struck', right_on = 'struck')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "#sns.set_palette('deep')\n",
    "plt.style.use('tableau-colorblind10')\n",
    "new_df.apply(lambda x: x*100/sum(x), axis = 1).plot(kind = 'bar', stacked = True, fontsize = 14, edgecolor = 'none')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2) \n",
    "plt.ylabel(\"Percent\", size = 16)\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(\"Diagnosis_by_strike.pdf\", format=\"pdf\", pad_inches = 0.5, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c34ef",
   "metadata": {},
   "source": [
    "Look at frequencies of dispositon and diagnosis by strike type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78599c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_disp = struck_floor['disposition'].value_counts()\n",
    "sf_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4f5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "so_disp = struck_object['disposition'].value_counts()\n",
    "print(so_disp[\"Released\"], so_disp[\"Admitted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac59750",
   "metadata": {},
   "source": [
    "Use an odds ratio contigency table to determine if the striking the floor has a higher risk of hospitalization than striking an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aaf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.contingency import odds_ratio\n",
    "res = odds_ratio([[sf_disp[\"Admitted\"],so_disp[\"Admitted\"]],[sf_disp[\"Released\"],so_disp[\"Released\"]]])\n",
    "print(res.statistic, res.confidence_interval(confidence_level=0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9d4e3",
   "metadata": {},
   "source": [
    "The odds of being admitted/hospitalized if a patient strikes the floor are 1.xx times (95% CI = 1.xx-1.xx) that of being admitted if a patient strikes an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46075b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_unknown['disposition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2fb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_diag = struck_object['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_diag = struck_floor['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83430da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_diag.sum() - sf_diag[\"Fracture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = odds_ratio([[sf_diag[\"Fracture\"],so_diag[\"Fracture\"]],[sf_diag.sum() - sf_diag[\"Fracture\"], so_diag.sum() - so_diag[\"Fracture\"]]])\n",
    "print(res.statistic, res.confidence_interval(confidence_level=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = odds_ratio([[sf_diag[\"Laceration\"],so_diag[\"Laceration\"]],[sf_diag.sum() - sf_diag[\"Laceration\"], so_diag.sum() - so_diag[\"Laceration\"]]])\n",
    "print(res.statistic, res.confidence_interval(confidence_level=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca78fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "struck_unknown['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible version of a stacke bar plot\n",
    "# struck_floor.groupby('disposition')['diagnosis'].value_counts(normalize=True).unstack('diagnosis').plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a734182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
